{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kuiaIPfTFz7",
        "outputId": "d6759385-a9e1-4a0c-8e87-b91b448d113e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Checking for Rust toolchain....\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m Cargo, the Rust package manager, is not installed or is not on PATH.\n",
            "  \u001b[31m   \u001b[0m This package requires Rust and Cargo to compile extensions. Install it through\n",
            "  \u001b[31m   \u001b[0m the system's package manager or via https://rustup.rs/\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting elevenlabs\n",
            "  Downloading elevenlabs-0.2.15-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from elevenlabs) (1.10.4)\n",
            "Requirement already satisfied: ipython>=7.0 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from elevenlabs) (8.2.0)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from elevenlabs) (2.28.2)\n",
            "Requirement already satisfied: backcall in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (0.2.0)\n",
            "Requirement already satisfied: decorator in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (0.18.1)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (0.1.2)\n",
            "Requirement already satisfied: pickleshare in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (3.0.20)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (2.11.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (61.2.0)\n",
            "Requirement already satisfied: stack-data in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (4.8.0)\n",
            "Requirement already satisfied: appnope in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from ipython>=7.0->elevenlabs) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.10->elevenlabs) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->elevenlabs) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->elevenlabs) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->elevenlabs) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->elevenlabs) (2022.12.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.0->elevenlabs) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.0->elevenlabs) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.0->elevenlabs) (0.2.5)\n",
            "Requirement already satisfied: executing in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from stack-data->ipython>=7.0->elevenlabs) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from stack-data->ipython>=7.0->elevenlabs) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from stack-data->ipython>=7.0->elevenlabs) (0.2.2)\n",
            "Requirement already satisfied: six in /Users/tristanjoslin/opt/anaconda3/lib/python3.9/site-packages (from asttokens->stack-data->ipython>=7.0->elevenlabs) (1.16.0)\n",
            "Installing collected packages: elevenlabs\n",
            "Successfully installed elevenlabs-0.2.15\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.4.0-cp39-cp39-macosx_10_9_x86_64.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q gradio\n",
        "!pip install -q openai\n",
        "!pip install -q gTTS\n",
        "!pip install elevenlabs\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_JE1eEyiTvY",
        "outputId": "7f55d3ec-64bc-4c71-da61-bdadfe63dfaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: apt-get\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y portaudio19-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-BuU0aHT8D5",
        "outputId": "596682a8-9218-4d64-9fd4-de4eb17d4215"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gradio'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/tristanjoslin/Downloads/Version_1.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tristanjoslin/Downloads/Version_1.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwhisper\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tristanjoslin/Downloads/Version_1.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgr\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tristanjoslin/Downloads/Version_1.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tristanjoslin/Downloads/Version_1.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import gradio as gr \n",
        "import time\n",
        "import warnings\n",
        "import json\n",
        "import openai\n",
        "import os\n",
        "import pygame\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import io\n",
        "from gtts import gTTS\n",
        "from elevenlabs import *\n",
        "from elevenlabs import save, generate, set_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mmrP8gWUFRK"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDZ0IV25UHY5"
      },
      "outputs": [],
      "source": [
        "openai.api_key = '<insert openai API key here'\n",
        "\n",
        "from elevenlabs import set_api_key\n",
        "set_api_key(\"<insert elevenlabs api key>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3cGz-wKUPIy",
        "outputId": "2ac6e6f7-0a38-4933-bb1f-73c3facab768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 128MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdVomkILURjN",
        "outputId": "066a73ec-ef6a-44ef-fbec-8d277015f624"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgTa0sTuUTkW",
        "outputId": "38f00345-37b5-49ff-b24b-c901257a647d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, lavfi, from 'anullsrc=r=44100:cl=mono':\n",
            "  Duration: N/A, start: 0.000000, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_u8, 44100 Hz, mono, u8, 352 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (pcm_u8 (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'Temp.mp3':\n",
            "  Metadata:\n",
            "    TSSE            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: mp3 (libmp3lame), 44100 Hz, mono, s16p\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 libmp3lame\n",
            "size=      39kB time=00:00:10.00 bitrate=  32.1kbits/s speed= 122x    \n",
            "video:0kB audio:39kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.568409%\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -f lavfi -i anullsrc=r=44100:cl=mono -t 10 -q:a 9 -acodec libmp3lame Temp.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQdENIjePpvu"
      },
      "outputs": [],
      "source": [
        "def speech_to_text(audio):\n",
        "  \n",
        "    language = 'en'\n",
        "\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    result_text = result.text\n",
        "    return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBp9Sqh6UXMS"
      },
      "outputs": [],
      "source": [
        "def chatgpt_api(input_text):\n",
        "\n",
        "        chat_completion = openai.ChatCompletion.create(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages= input_text,\n",
        "              temperature=.5,\n",
        "              max_tokens=100,\n",
        "              top_p=1,\n",
        "              frequency_penalty=0,\n",
        "              presence_penalty=0\n",
        "              )\n",
        "\n",
        "        reply = chat_completion.choices[0].message.content\n",
        "        \n",
        "        return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbteQOUdrzVO"
      },
      "outputs": [],
      "source": [
        "def text_to_speech(out_result, language = 'en'):\n",
        "\n",
        "    audio = generate(\n",
        "        text=out_result,\n",
        "        voice=\"Rachel\",\n",
        "        model=\"eleven_monolingual_v1\"\n",
        "        )\n",
        "\n",
        "    save(\n",
        "      audio,\n",
        "      'Temp.mp3'\n",
        "    ) \n",
        "    \n",
        "    return \"Temp.mp3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLPHVw1JiSsp"
      },
      "outputs": [],
      "source": [
        "# Instantiate conversation_history\n",
        "# Set initial prompt\n",
        "conversation_history = [{\"role\": \"system\", \"content\": \"You are a sassy and acid conversational chatbot. Keep the conversation going asking questions back. Begin every answer with 'bruh'\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si9rhsq4m-_n"
      },
      "outputs": [],
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    global conversation_history\n",
        "\n",
        "    # Extract question text from voice\n",
        "    question_text = speech_to_text(audio)\n",
        "\n",
        "    # Append question_text to conversation_history\n",
        "    conversation_history.append(\n",
        "            {\"role\": \"user\", \"content\": question_text},\n",
        "        )\n",
        "\n",
        "    # Feed ChatOpenAI with conversation_history\n",
        "    answer_text = chatgpt_api(conversation_history)\n",
        "\n",
        "    # Synthetize voice\n",
        "    voice_answer = text_to_speech(answer_text)\n",
        "\n",
        "    # Append answer_text to conversation_history\n",
        "    conversation_history.append(\n",
        "            {\"role\": \"assistant\", \"content\": answer_text},\n",
        "        )\n",
        "\n",
        "\n",
        "    return [question_text, answer_text, voice_answer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "3u_ODU95UgVY",
        "outputId": "8819f117-9dbe-4893-e083-7cac83e69a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7860, \"/\", \"100%\", 500, false, window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_1 = gr.Textbox(label=\"Speech to Text\")\n",
        "output_2 = gr.Textbox(label=\"ChatGPT Output\")\n",
        "output_3 = gr.Audio(\"Temp.mp3\")\n",
        "\n",
        "gr.Interface(\n",
        "    title = 'OpenAI Whisper and ChatGPT ASR Gradio Web UI', \n",
        "    fn=transcribe, \n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "\n",
        "    outputs=[\n",
        "        output_1,  output_2, output_3\n",
        "    ],\n",
        "    live=True).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVOWpxtr1wZY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
